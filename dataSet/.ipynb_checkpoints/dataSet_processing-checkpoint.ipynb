{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2587e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "base_input = r'E:\\eep564\\proj\\TinyML\\dataset_OG\\SisFall'\n",
    "base_output = r'E:\\eep564\\proj\\TinyML\\dataSet'\n",
    "subfolders = ['ADL', 'FALL']\n",
    "\n",
    "for subfolder in subfolders:\n",
    "    input_path = os.path.join(base_input, subfolder)\n",
    "    output_path = os.path.join(base_output, subfolder)\n",
    "\n",
    "    for filename in os.listdir(input_path):\n",
    "        if filename.endswith('.txt'):\n",
    "            input_file = os.path.join(input_path, filename)\n",
    "            output_file = os.path.join(output_path, filename)\n",
    "\n",
    "            with open(input_file, 'r', encoding='utf-8') as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "            new_lines = []\n",
    "            for line in lines:\n",
    "                numbers = line.strip().split(',')\n",
    "                if len(numbers) >= 9:\n",
    "                    new_numbers = numbers[:6] # keep these 2 3-axis accelerometer data\n",
    "                    new_lines.append(','.join(new_numbers) + '\\n')\n",
    "\n",
    "            with open(output_file, 'w', encoding='utf-8') as f:\n",
    "                f.writelines(new_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efa41889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using \"The Largest SMV\" to select 3s' data (200Hz)\n",
    "\n",
    "def compute_mod(x, y, z):\n",
    "    return math.sqrt(x**2 + y**2 + z**2)\n",
    "\n",
    "# If there are less than 300 lines before or after the center point, it will be automatically filled from the beginning or end.\n",
    "def get_centered_segment(data, center_idx, window_size=601):\n",
    "    half = window_size // 2\n",
    "    total_len = len(data)\n",
    "    start = center_idx - half\n",
    "    end = center_idx + half + 1\n",
    "\n",
    "    # Initial slicing (may go out of bounds)\n",
    "    segment = data[max(0, start):min(end, total_len)]\n",
    "\n",
    "    # If the segment is shorter than desired, pad from the opposite end\n",
    "    while len(segment) < window_size:\n",
    "        if start < 0:\n",
    "            # Not enough data before the center → pad from the tail\n",
    "            need = window_size - len(segment)\n",
    "            tail_part = data[min(total_len, end):min(total_len, end + need)]\n",
    "            segment.extend(tail_part)\n",
    "            end += len(tail_part)\n",
    "        elif end > total_len:\n",
    "            # Not enough data after the center → pad from the head\n",
    "            need = window_size - len(segment)\n",
    "            head_part = data[max(0, start - need):max(0, start)]\n",
    "            segment = head_part + segment\n",
    "            start -= len(head_part)\n",
    "        else:\n",
    "            break  # Segment is complete\n",
    "\n",
    "    return segment[:window_size]  # Ensure exact length by truncating if necessary\n",
    "\n",
    "base_path = base_output\n",
    "\n",
    "for subfolder in subfolders:\n",
    "    folder = os.path.join(base_path, subfolder)\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.txt'):\n",
    "            filepath = os.path.join(folder, filename)\n",
    "\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "            # transfer to list\n",
    "            data = []\n",
    "            for line in lines:\n",
    "                try:\n",
    "                    nums = list(map(float, line.strip().split(',')))\n",
    "                    if len(nums) == 6:\n",
    "                        data.append(nums)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "            # SMV(Support Magnitude Vector)\n",
    "            avg_mods = []\n",
    "            for nums in data:\n",
    "                mod1 = compute_mod(nums[0], nums[1], nums[2])\n",
    "                mod2 = compute_mod(nums[3], nums[4], nums[5])\n",
    "                avg_mod = (mod1 + mod2) / 2 # Use 2 accelerometers' avarage SMV to combine\n",
    "                avg_mods.append(avg_mod)\n",
    "\n",
    "            if len(avg_mods) == 0:\n",
    "                print(f\"wrong：{filepath}\")\n",
    "                continue\n",
    "\n",
    "            max_idx = avg_mods.index(max(avg_mods))\n",
    "\n",
    "            # extract ±300 lines（601 lines in all）\n",
    "            selected_data = get_centered_segment(data, max_idx, 601)\n",
    "\n",
    "            # write back\n",
    "            with open(filepath, 'w', encoding='utf-8') as f:\n",
    "                for nums in selected_data:\n",
    "                    f.write(','.join(map(str, nums)) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47aa1c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transfer from txt to csv (both exist)\n",
    "for subfolder in subfolders:\n",
    "    input_folder = os.path.join(base_path, subfolder)\n",
    "    output_folder = os.path.join(base_path, f\"{subfolder}_CSV\")\n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith('.txt'):\n",
    "            txt_path = os.path.join(input_folder, filename)\n",
    "            csv_filename = filename.replace('.txt', '.csv')\n",
    "            csv_path = os.path.join(output_folder, csv_filename)\n",
    "\n",
    "            with open(txt_path, 'r', encoding='utf-8') as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "            with open(csv_path, 'w', encoding='utf-8') as f:\n",
    "                for line in lines:\n",
    "                    f.write(line.strip() + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fba49a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:TinyML]",
   "language": "python",
   "name": "tinyml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
